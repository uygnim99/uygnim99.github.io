<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[논문리뷰] Understanding Diffusion Model: The Unified Perspective | Mingdarin</title>
<meta name=keywords content="diffusion"><meta name=description content="Understanding Diffusion Model: The Unified Perspective [Paper]
Author: Calvin Luo
Google Research, Brain Team
25 Aug 2022
diffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.
생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.
Introduction: Generative Models 생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 새로운 데이터들을 sampling을 통해 생성할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음."><meta name=author content><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.4929463062f2742fc2d95440d7196025c18ff76bbb3ea52aecb47080ad777ed5.css integrity="sha256-SSlGMGLydC/C2VRA1xlgJcGP92u7PqUq7LRwgK13ftU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://uygnim99.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://uygnim99.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://uygnim99.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://uygnim99.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://uygnim99.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="[논문리뷰] Understanding Diffusion Model: The Unified Perspective"><meta property="og:description" content="Understanding Diffusion Model: The Unified Perspective [Paper]
Author: Calvin Luo
Google Research, Brain Team
25 Aug 2022
diffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.
생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.
Introduction: Generative Models 생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 새로운 데이터들을 sampling을 통해 생성할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음."><meta property="og:type" content="article"><meta property="og:url" content="https://uygnim99.github.io/post/diffusion/2024-03-12-understanding-diffusion-model/"><meta property="og:image" content="https://uygnim99.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-03-12T00:00:00+00:00"><meta property="article:modified_time" content="2024-03-12T00:00:00+00:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://uygnim99.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[논문리뷰] Understanding Diffusion Model: The Unified Perspective"><meta name=twitter:description content="Understanding Diffusion Model: The Unified Perspective [Paper]
Author: Calvin Luo
Google Research, Brain Team
25 Aug 2022
diffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.
생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.
Introduction: Generative Models 생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 새로운 데이터들을 sampling을 통해 생성할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://uygnim99.github.io/post/"},{"@type":"ListItem","position":2,"name":"[논문리뷰] Understanding Diffusion Model: The Unified Perspective","item":"https://uygnim99.github.io/post/diffusion/2024-03-12-understanding-diffusion-model/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[논문리뷰] Understanding Diffusion Model: The Unified Perspective","name":"[논문리뷰] Understanding Diffusion Model: The Unified Perspective","description":"Understanding Diffusion Model: The Unified Perspective [Paper]\nAuthor: Calvin Luo\nGoogle Research, Brain Team\n25 Aug 2022\ndiffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.\n생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.\nIntroduction: Generative Models 생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 새로운 데이터들을 sampling을 통해 생성할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음.","keywords":["diffusion"],"articleBody":" Understanding Diffusion Model: The Unified Perspective [Paper]\nAuthor: Calvin Luo\nGoogle Research, Brain Team\n25 Aug 2022\ndiffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.\n생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.\nIntroduction: Generative Models 생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 새로운 데이터들을 sampling을 통해 생성할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음.\n여러가지 방식의 생성모델들:\nGAN: adversarial한 방식을 이용해 분포도 학습 autoregressive model, VAE: likelihood-based 모델 Score-based generative models 이중에서 diffusion은 likelihood-based모델과 score-based모델 두가지의 관점으로 해석이 가능하고, 먼저 이번 글에서는 likelihood 관점의 해석을 분석해보자.\nELBO, VAE and Hierarchical VAE 어떤 데이터가 있으면, 이를 몇가지의 특징을 이용해 표현하거나, 반대로 이러한 특징들을 이용해 데이터를 생성할 수 있다. 이러한 특징들이 latent variable z에 해당한다. 저차원의 latent들로 데이터를 표현할 수 있으면, latent들이 semantic할 것이라고 생각할 수 있다.\n우리가 관찰한 데이터 x와 latent variable z의 joint distribution인 $p(x,z)$를 생각해 보자. 이를 이용해 우리가 구하고자 하는 p(x)를 두가지 방식으로 나타낼 수 있다:\n$$ \\begin{align} p(x) = \\int p(x,z)dz \\end{align} $$ $$ \\begin{align} p(x) = \\cfrac{p(x,z)}{p(z|x)} \\end{align} $$\n하지만, 위의 식들을 이용해 p(x)를 직접 구하기는 어려움. (1)의 경우 모든 latent z에 대해서 joint distribution을 구하기 어렵고, (2)의 경우 ground truth latent encoder $p(z|x)$를 얻을 수 없기 때문이다.\nlatent encoder $p(z|x)$: sample x가 주어졌을때의 z의 분포 생성모델의 목표는 x의 분포를 알아내는 것이고, 이는 결국 $\\log{p(x)}$를 최대화 시켜야 함.\np(x)는 likelihood이다. likelihood(가능도, 우도)와 probability(확률)은 비슷한 개념이지만, 확실히 차이가 있는 개념이다.\nprobability: 확률분포를 고정시켰을 때, 그 분포에 따르면 이 값이 나올 확률이 얼마나 되는가?\nlikelihood: 관찰한 값들을 토대로 이 값들이 어떤 확률분포에서 생성되었을까?\n결국 log-likelihood인 $\\log{p(x)}$을 최대화시켜야 하는 것이 생성모델의 목표이다.\nELBO를 식으로 표현하면 다음과 같다:\n$$ \\begin{align} \\log{p(x)} \\geq \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)}{q_\\phi(z|x)}}\\bigg] \\end{align} $$ $q_\\phi(z|x)$: flexible approximate variational distribution with parameter $\\phi$ = true posterior $p(z|x)$를 추정하는 parameterizable model variational: 변분. (추후 정리 예정)\nposterior: 관측 값이 주어졌을 때, 구하고자 하는 대상이 나올 확률\nprior: 구하고자 하는 대상 자체에 대한 확률\n$\\log{p(x)}$를 직접적으로 계산해 최대화 하는 대신, Lower bound를 최대화하는 방향으로 학습을 진행한다. 이 과정은 $q_\\phi(z|x)$가 $p(z|x)$를 추정하도록 $\\phi$를 학습하는 것으로 볼 수 있다.\n위의 부등식을 유도하는 방식은 두가지이다. 첫번째로, Jensen’s Inequality를 이용하는 방식은 다음과 같다:\n$$ \\begin{align} \\log{p(x)} \u0026= \\log{\\int p(x,z)dz} \u0026 \\\\ \u0026= \\log{\\int\\cfrac{p(x,z)q_\\phi(z|x)}{q_\\phi(z|x)}dz} \\\\ \u0026= \\log{\\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\cfrac{p(x,z)}{q_\\phi(z|x)}}\\bigg]\\\\ \u0026\\geq \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)}{q_\\phi(z|x)}}\\bigg] \u0026 \\leftarrow \\mathrm{Jenson's \\ Inequality} \\end{align} $$ 이 방식은 수식에 대한 semantic한 의미를 찾기가 어렵다. 대신에, 두번째 방식으로 유도하는 과정은 다음과 같다:\n$$ \\begin{align} \\log{p(x)} \u0026= \\log{p(x)}\\int{q_\\phi(z|x)dz} \\\\ \u0026= \\int{q_\\phi(z|x)(\\log{p(x)})dz} \\\\ \u0026= \\mathbb{E}_{q_\\phi(z|x)}[\\log{p(x)}] \\\\ \u0026= \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)}{p(z|x)}}\\bigg] \\\\ \u0026= \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)q_\\phi(z|x)}{p(z|x)q_\\phi(z|x)}}\\bigg] \\\\ \u0026= \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)}{q_\\phi(z|x)}}\\bigg] + \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{q_\\phi(z|x)}{p(z|x)}}\\bigg] \\\\ \u0026= \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)}{q_\\phi(z|x)}}\\bigg] + D_{KL}(q_\\phi(z|x)||p(z|x)) \\\\ \u0026\\geq \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)}{q_\\phi(z|x)}}\\bigg] \\end{align} $$ (13) -\u003e (14): KL Divergence의 정의.\n(14) -\u003e (15): KL Divergence는 항상 0보다 크다.\n마지막 부분을 보면, $q_\\phi(z|x)$가 $p(z|x)$의 분포도가 유사해질 수록 KL Divergence항이 0에 가까워진다. 근데, $p(z|x)$을 모르기 때문에 KL Divergence항을 직접 최소화하는 것은 어렵다. 대신에, ELBO항을 최대화 시키도록 parameter $\\phi$를 optimize하는 것은 가능하다.\n$\\log{p(x)}$은 parameter $\\phi$에 영향을 받지 않기 때문에 값이 변하지 않는다. 결국 ELBO 항을 최대화 시키는 과정이 KL Divergence항을 최소화 시키게 되고, 이는 $q_\\phi(z|x)$가 $p(z|x)$의 분포도가 유사해지는 방향으로 최적화가 이루어진다.\nVariational Autoencoders (VAE) 생성모델의 한 종류로, encoder($q_\\phi(z|x)$)을 통해 sample data를 latent vector로 변환하고, 이를 다시 decoder($p_\\theta(x|z)$)을 통해 본래의 sample data를 복원하는 과정을 통해 학습을 진행한다. 그리고 latent vector을 조절해 decoder을 거쳐 새로운 데이터를 sampling 할 수 있다. 이때, VAE는 ELBO를 직접 최대화하는 방식으로 optimize한다. ELBO항을 정리하면 다음과 같다:\n$$ \\begin{align} \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(x,z)}{q_\\phi(z|x)}}\\bigg] \u0026= \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p_\\theta(x|z)p(z)}{q_\\phi(z|x)}}\\bigg] \\\\ \u0026= \\mathbb{E}_{q_\\phi(z|x)}[\\log{p_\\theta(x|z)}] + \\mathbb{E}_{q_\\phi(z|x)}\\bigg[\\log{\\cfrac{p(z)}{q_\\phi(z|x)}}\\bigg] \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_\\phi(z|x)}[\\log{p_\\theta(x|z)}]}_{\\footnotesize\\mathrm{reconstruction \\ term}} + \\underbrace{D_{KL}(q_\\phi(z|x) || p(z))}_{\\footnotesize\\mathrm{prior \\ matching \\ term}} \\end{align} $$ reconstruction term: 식 그대로 말로 풀면, “z의 분포가 $q_\\phi(z|x)$ 일때의 $p_\\theta(x|z)$의 기댓값\"이다. 해석해보면 latent vector z로 변환했을 때, 이 값을 이용해 다시 x가 복원이 될 확률에 대한 기댓값이다. 결국, parameter $\\phi$는 latent vector z를 잘 생성하도록, parameter $\\theta$는 z에서 x로 잘 복원하도록 optimize하는 항으로 볼 수 있다.\nprior matching term: encoder $q_\\phi(z|x)$가 latent prior $p(z)$와 얼마나 유사하냐를 의미한다. 이 항을 최소화 시키려면, $q_\\phi(z|x)$가 $p(z)$의 분포와 유사하도록 optimize해야 한다.\n","wordCount":"642","inLanguage":"en","datePublished":"2024-03-12T00:00:00Z","dateModified":"2024-03-12T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://uygnim99.github.io/post/diffusion/2024-03-12-understanding-diffusion-model/"},"publisher":{"@type":"Organization","name":"Mingdarin","logo":{"@type":"ImageObject","url":"https://uygnim99.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://uygnim99.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://uygnim99.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://uygnim99.github.io/archive/ title=Archive><span>Archive</span></a></li><li><a href=https://uygnim99.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://uygnim99.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://uygnim99.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://uygnim99.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://uygnim99.github.io/post/>Posts</a></div><h1 class=post-title>[논문리뷰] Understanding Diffusion Model: The Unified Perspective</h1><div class=post-meta><span title='2024-03-12 00:00:00 +0000 UTC'>Date: March 12, 2024</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#understanding-diffusion-model-the-unified-perspective>Understanding Diffusion Model: The Unified Perspective</a></li><li><a href=#introduction-generative-models>Introduction: Generative Models</a></li><li><a href=#elbo-vae-and-hierarchical-vae>ELBO, VAE and Hierarchical VAE</a></li><li><a href=#variational-autoencoders-vae>Variational Autoencoders (VAE)</a></li></ul></li></ul></nav></div></details></div><div class=post-content><style>r{color:Red}o{color:Orange}b{color:Blue}</style><h3 id=understanding-diffusion-model-the-unified-perspective>Understanding Diffusion Model: The Unified Perspective<a hidden class=anchor aria-hidden=true href=#understanding-diffusion-model-the-unified-perspective>#</a></h3><blockquote><p>[<a href=https://arxiv.org/abs/2208.11970>Paper</a>]<br>Author: Calvin Luo<br>Google Research, Brain Team<br>25 Aug 2022</p></blockquote><hr><p>diffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.</p><p>생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.</p><h3 id=introduction-generative-models>Introduction: Generative Models<a hidden class=anchor aria-hidden=true href=#introduction-generative-models>#</a></h3><p>생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 <strong>새로운 데이터들을 sampling을 통해 생성</strong>할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음.</p><p>여러가지 방식의 생성모델들:</p><ul><li>GAN: adversarial한 방식을 이용해 분포도 학습</li><li>autoregressive model, VAE: likelihood-based 모델</li><li>Score-based generative models</li></ul><p>이중에서 diffusion은 likelihood-based모델과 score-based모델 두가지의 관점으로 해석이 가능하고, 먼저 이번 글에서는 likelihood 관점의 해석을 분석해보자.</p><h3 id=elbo-vae-and-hierarchical-vae>ELBO, VAE and Hierarchical VAE<a hidden class=anchor aria-hidden=true href=#elbo-vae-and-hierarchical-vae>#</a></h3><p>어떤 데이터가 있으면, 이를 몇가지의 특징을 이용해 표현하거나, 반대로 이러한 특징들을 이용해 데이터를 생성할 수 있다. 이러한 특징들이 latent variable <strong>z</strong>에 해당한다. 저차원의 latent들로 데이터를 표현할 수 있으면, latent들이 semantic할 것이라고 생각할 수 있다.</p><p>우리가 관찰한 데이터 <strong>x</strong>와 latent variable <strong>z</strong>의 joint distribution인 $p(x,z)$를 생각해 보자. 이를 이용해 우리가 구하고자 하는 p(x)를 두가지 방식으로 나타낼 수 있다:</p><p>$$
\begin{align}
p(x) = \int p(x,z)dz
\end{align}
$$
$$
\begin{align}
p(x) = \cfrac{p(x,z)}{p(z|x)}
\end{align}
$$</p><p>하지만, 위의 식들을 이용해 p(x)를 직접 구하기는 어려움. (1)의 경우 모든 latent <strong>z</strong>에 대해서 joint distribution을 구하기 어렵고, (2)의 경우 ground truth latent encoder $p(z|x)$를 얻을 수 없기 때문이다.</p><ul><li>latent encoder $p(z|x)$: sample x가 주어졌을때의 z의 분포</li></ul><p>생성모델의 목표는 x의 분포를 알아내는 것이고, 이는 결국 $\log{p(x)}$를 최대화 시켜야 함.</p><p>p(x)는 likelihood이다. likelihood(가능도, 우도)와 probability(확률)은 비슷한 개념이지만, 확실히 차이가 있는 개념이다.</p><blockquote><p><strong>probability</strong>: 확률분포를 고정시켰을 때, 그 분포에 따르면 이 값이 나올 확률이 얼마나 되는가?<br><strong>likelihood</strong>: 관찰한 값들을 토대로 이 값들이 어떤 확률분포에서 생성되었을까?</p></blockquote><p>결국 log-likelihood인 $\log{p(x)}$을 최대화시켜야 하는 것이 생성모델의 목표이다.</p><p>ELBO를 식으로 표현하면 다음과 같다:</p>$$
\begin{align}
\log{p(x)} \geq \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)}{q_\phi(z|x)}}\bigg]
\end{align}
$$<ul><li>$q_\phi(z|x)$: flexible approximate <strong>variational</strong> distribution with parameter $\phi$ = true posterior $p(z|x)$를 추정하는 parameterizable model</li></ul><blockquote><p><strong>variational</strong>: 변분. (추후 정리 예정)<br><strong>posterior</strong>: 관측 값이 주어졌을 때, 구하고자 하는 대상이 나올 확률<br><strong>prior</strong>: 구하고자 하는 대상 자체에 대한 확률</p></blockquote><p>$\log{p(x)}$를 직접적으로 계산해 최대화 하는 대신, Lower bound를 최대화하는 방향으로 학습을 진행한다. 이 과정은 $q_\phi(z|x)$가 $p(z|x)$를 추정하도록 $\phi$를 학습하는 것으로 볼 수 있다.</p><p>위의 부등식을 유도하는 방식은 두가지이다. 첫번째로, Jensen&rsquo;s Inequality를 이용하는 방식은 다음과 같다:</p>$$
\begin{align}
\log{p(x)} &= \log{\int p(x,z)dz} & \\
    &= \log{\int\cfrac{p(x,z)q_\phi(z|x)}{q_\phi(z|x)}dz} \\
&= \log{\mathbb{E}_{q_\phi(z|x)}\bigg[\cfrac{p(x,z)}{q_\phi(z|x)}}\bigg]\\
&\geq \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)}{q_\phi(z|x)}}\bigg] & \leftarrow \mathrm{Jenson's \ Inequality}
\end{align}
$$<p>이 방식은 수식에 대한 semantic한 의미를 찾기가 어렵다. 대신에, 두번째 방식으로 유도하는 과정은 다음과 같다:</p>$$
\begin{align}
\log{p(x)} &= \log{p(x)}\int{q_\phi(z|x)dz} \\
&= \int{q_\phi(z|x)(\log{p(x)})dz} \\
&= \mathbb{E}_{q_\phi(z|x)}[\log{p(x)}] \\
&= \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)}{p(z|x)}}\bigg] \\
&= \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)q_\phi(z|x)}{p(z|x)q_\phi(z|x)}}\bigg] \\
&= \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)}{q_\phi(z|x)}}\bigg] + \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{q_\phi(z|x)}{p(z|x)}}\bigg] \\
&= \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)}{q_\phi(z|x)}}\bigg] + D_{KL}(q_\phi(z|x)||p(z|x)) \\
&\geq \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)}{q_\phi(z|x)}}\bigg]
\end{align}
$$<blockquote><p>(13) -> (14): KL Divergence의 정의.<br>(14) -> (15): KL Divergence는 항상 0보다 크다.</p></blockquote><p>마지막 부분을 보면, $q_\phi(z|x)$가 $p(z|x)$의 분포도가 유사해질 수록 KL Divergence항이 0에 가까워진다. 근데, $p(z|x)$을 모르기 때문에 KL Divergence항을 직접 최소화하는 것은 어렵다. 대신에, ELBO항을 최대화 시키도록 parameter $\phi$를 optimize하는 것은 가능하다.</p><p>$\log{p(x)}$은 parameter $\phi$에 영향을 받지 않기 때문에 값이 변하지 않는다. 결국 ELBO 항을 최대화 시키는 과정이 KL Divergence항을 최소화 시키게 되고, 이는 $q_\phi(z|x)$가 $p(z|x)$의 분포도가 유사해지는 방향으로 최적화가 이루어진다.</p><h3 id=variational-autoencoders-vae>Variational Autoencoders (VAE)<a hidden class=anchor aria-hidden=true href=#variational-autoencoders-vae>#</a></h3><p>생성모델의 한 종류로, encoder(<strong>$q_\phi(z|x)$</strong>)을 통해 sample data를 latent vector로 변환하고, 이를 다시 decoder(<strong>$p_\theta(x|z)$</strong>)을 통해 본래의 sample data를 복원하는 과정을 통해 학습을 진행한다. 그리고 latent vector을 조절해 decoder을 거쳐 새로운 데이터를 sampling 할 수 있다. 이때, VAE는 ELBO를 직접 최대화하는 방식으로 optimize한다. ELBO항을 정리하면 다음과 같다:</p>$$
\begin{align}
\mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(x,z)}{q_\phi(z|x)}}\bigg] &= \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p_\theta(x|z)p(z)}{q_\phi(z|x)}}\bigg] \\
&= \mathbb{E}_{q_\phi(z|x)}[\log{p_\theta(x|z)}] + \mathbb{E}_{q_\phi(z|x)}\bigg[\log{\cfrac{p(z)}{q_\phi(z|x)}}\bigg] \\
&= \underbrace{\mathbb{E}_{q_\phi(z|x)}[\log{p_\theta(x|z)}]}_{\footnotesize\mathrm{reconstruction \ term}} + \underbrace{D_{KL}(q_\phi(z|x) || p(z))}_{\footnotesize\mathrm{prior \ matching \ term}}
\end{align}
$$<blockquote><p><strong>reconstruction term</strong>: 식 그대로 말로 풀면, &ldquo;z의 분포가 $q_\phi(z|x)$ 일때의 $p_\theta(x|z)$의 기댓값"이다. 해석해보면 latent vector z로 변환했을 때, 이 값을 이용해 다시 x가 복원이 될 확률에 대한 기댓값이다. 결국, parameter $\phi$는 latent vector z를 잘 생성하도록, parameter $\theta$는 z에서 x로 잘 복원하도록 optimize하는 항으로 볼 수 있다.<br><strong>prior matching term</strong>: encoder $q_\phi(z|x)$가 latent prior $p(z)$와 얼마나 유사하냐를 의미한다. 이 항을 최소화 시키려면, $q_\phi(z|x)$가 $p(z)$의 분포와 유사하도록 optimize해야 한다.</p></blockquote></div><footer class=post-footer><ul class=post-tags><li><a href=https://uygnim99.github.io/tags/diffusion/>diffusion</a></li></ul><nav class=paginav><a class=next href=https://uygnim99.github.io/post/relit/relit-base/><span class=title>Next »</span><br><span>relit</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://uygnim99.github.io/>Mingdarin</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>