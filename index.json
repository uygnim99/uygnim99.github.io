[{"content":" Understanding Diffusion Model: The Unified Perspective [Paper]\nAuthor: Calvin Luo\nGoogle Research, Brain Team\n25 Aug 2022\ndiffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.\n생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.\nIntroduction: Generative Models 생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 새로운 데이터들을 sampling을 통해 생성할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음.\n여러가지 방식의 생성모델들:\nGAN: adversarial한 방식을 이용해 분포도 학습 autoregressive model, VAE: likelihood-based 모델 Score-based generative models 이중에서 diffusion은 likelihood-based모델과 score-based모델 두가지의 관점으로 해석이 가능하고, 먼저 이번 글에서는 likelihood 관점의 해석을 분석해보자.\nELBO, VAE and Hierarchical VAE 어떤 데이터가 있으면, 이를 몇가지의 특징을 이용해 표현하거나, 반대로 이러한 특징들을 이용해 데이터를 생성할 수 있다. 이러한 특징들이 latent variable z에 해당한다. 저차원의 latent들로 데이터를 표현할 수 있으면, latent들이 semantic할 것이라고 생각할 수 있다.\n우리가 관찰한 데이터 x와 latent variable z의 joint distribution인 p(x,z)를 생각해 보자. 이를 이용해 우리가 구하고자 하는 p(x)를 두가지 방식으로 나타낼 수 있다:\n$$ \\begin{equation} p(x) = \\int p(x,z)dz \\end{equation} $$ $$ \\begin{equation} p(x) = \\cfrac{p(x,z)}{p(z|x)} \\end{equation} $$\n하지만, 위의 식들을 이용해 p(x)를 직접 구하기는 어려움. (1)의 경우 모든 latent z에 대해서 joint distribution을 구하기 어렵고, (2)의 경우 GT(ground truth) latent encoder p(z|x)를 얻을 수 없기 때문이다.\nlatent encoder p(z|x): x가 주어졌을때의 z의 분포\nx를 latent variable z로 변환해주는 encoder로 볼 수 있음.\n생성모델의 목표는 x의 분포를 알아내는 것이고, 이는 결국 $$\\log{p(x)}$$를 최대화 시켜야 함.\np(x): likelihood\nlikelihood(가능도, 우도) \u0026lt;-\u0026gt; probability(확률)\nprobability: 확률분포를 고정시켰을 때, 그 분포에 따르면 이 값이 나올 확률이 얼마나 되는가?\nlikelihood: 관찰한 값들을 토대로 이 값들이 어떤 확률분포에서 생성되었을까?\n결국 log-likelihood인 \\(\\log{p(x)}\\)을 최대화시켜야함.\n","permalink":"https://uygnim99.github.io/post/diffusion/2024-03-12-understanding-diffusion-model/","summary":"Understanding Diffusion Model: The Unified Perspective [Paper]\nAuthor: Calvin Luo\nGoogle Research, Brain Team\n25 Aug 2022\ndiffusion 분야 최신 논문을 읽기 전에, 리뷰논문을 공부하며 VAE부터 Diffusion 모델까지 수식과 함께 이해해 봅시다.\n생성모델이라는 개념을 제대로 접한 것은 이 논문이 처음이라, 최대한 제가 이해한 대로 글을 작성했습니다.\nIntroduction: Generative Models 생성모델의 목적은 관찰한 sample x에 대해서, x의 분포도를 알아내는 것이다. 이를 이용해 새로운 데이터들을 sampling을 통해 생성할 수도 있고, 어떤 데이터에 대한 likelihood를 계산할 수도 있음.","title":"[논문리뷰] Understanding Diffusion Model: The Unified Perspective"},{"content":"","permalink":"https://uygnim99.github.io/post/relit/relit-base/","summary":"","title":"relit"},{"content":"paper: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\n앞으로 리뷰하고 공부하게 될 논문들의 기본 베이스 개념인 NeRF에 대해서 간단히 알아봅시다.\nNeural Radiance Field 논문에서 다루는 view synthesis 테스크는 어떤 물체를 여러 각도로 찍은 사진을 이용하여 새로운 각도에서 물체를 바라본 이미지를 얻어내는 작업입니다.\nMLP를 사용해 2D image를 input으로 활용하여 3D object의 color값과 volume density값을 예측하고, 이를 이용해 novel view image를 얻어내는 모델입니다.\n논문을 이해하기 위해선 camera model, volume rendering, ray tracing등의 컴퓨터 비전 관련 지식들이 필요하기 때문에, 차후에 하나씩 정리해서 추가해 보도록 하고, 이 글에서는 논문에 쓰인 기법들 위주로 설명해 보도록 하겠습니다.\nModel Pipeline please 10트\n","permalink":"https://uygnim99.github.io/post/nerf/nerf-base/","summary":"paper: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\n앞으로 리뷰하고 공부하게 될 논문들의 기본 베이스 개념인 NeRF에 대해서 간단히 알아봅시다.\nNeural Radiance Field 논문에서 다루는 view synthesis 테스크는 어떤 물체를 여러 각도로 찍은 사진을 이용하여 새로운 각도에서 물체를 바라본 이미지를 얻어내는 작업입니다.\nMLP를 사용해 2D image를 input으로 활용하여 3D object의 color값과 volume density값을 예측하고, 이를 이용해 novel view image를 얻어내는 모델입니다.\n논문을 이해하기 위해선 camera model, volume rendering, ray tracing등의 컴퓨터 비전 관련 지식들이 필요하기 때문에, 차후에 하나씩 정리해서 추가해 보도록 하고, 이 글에서는 논문에 쓰인 기법들 위주로 설명해 보도록 하겠습니다.","title":"NeRF 기본 개념 설명"}]